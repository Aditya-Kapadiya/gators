{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison between Pandas, Dask, and Koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from pandas.testing import assert_series_equal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import treelite\n",
    "import treelite_runtime\n",
    "import dill\n",
    "import joblib\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier as RFCSpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gators** imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "from gators.data_cleaning import (\n",
    "    DropColumns,\n",
    "    Replace,\n",
    ")\n",
    "# imputers\n",
    "from gators.imputers import (\n",
    "    NumericsImputer, \n",
    "    ObjectImputer,\n",
    ")\n",
    "# encoders\n",
    "from gators.encoders import (\n",
    "    WOEEncoder,\n",
    ")\n",
    "# binning\n",
    "from gators.binning import (\n",
    "    BinRareCategories,\n",
    "    BinSingleTargetClassCategories,\n",
    "    Binning,\n",
    "    CustomBinning,\n",
    "    QuantileBinning,\n",
    "    TreeBinning,\n",
    ")\n",
    "# feature generation\n",
    "from gators.feature_generation import (\n",
    "    PolynomialFeatures,\n",
    "    ElementaryArithmetics,\n",
    "    PolynomialObjectFeatures,\n",
    "    IsNull,\n",
    ")\n",
    "from gators.feature_generation_str import (\n",
    "    StringContains,\n",
    "    StringLength,\n",
    "    Extract,\n",
    "    SplitExtract,\n",
    ")\n",
    "# feature selection\n",
    "from gators.feature_selection import (\n",
    "    SelectFromModel,\n",
    "    InformationValue\n",
    ")\n",
    "# model building\n",
    "from gators.model_building import (\n",
    "    TrainTestSplit,\n",
    "    XGBBoosterBuilder,\n",
    "    XGBTreeliteDumper,\n",
    ")\n",
    "# pipeline\n",
    "from gators.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('SplitExtractName', SplitExtract(['Name'], [', '], [1], ['Dummy'])),\n",
    "    ('SplitExtractTitle', SplitExtract(['Dummy'], ['.'], [0], ['Title'])),\n",
    "    ('StringLength', StringLength(columns=['Cabin', 'Ticket'])),\n",
    "    ('DropColumns', DropColumns(['Name', 'Dummy', 'Cabin', 'Ticket'])),\n",
    "    ('ObjectImputer', ObjectImputer(strategy='constant', value='MISSING')),\n",
    "    ('BinSingleTargetClassCategories', BinSingleTargetClassCategories()),\n",
    "    ('NumericsImputer', NumericsImputer(strategy='mean')),\n",
    "    ('ElementaryArithmetics', ElementaryArithmetics(\n",
    "        operator='+',\n",
    "        columns_a=['SibSp'], \n",
    "        columns_b=['Parch'], \n",
    "        column_names=['FamilySize'])),\n",
    "    ('TreeBinning', TreeBinning(\n",
    "        tree=DecisionTreeClassifier(max_depth=2, min_samples_leaf=25),\n",
    "        inplace=True)),\n",
    "    ('PolynomialObjectFeatures', PolynomialObjectFeatures(\n",
    "        columns=[\n",
    "            'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', \n",
    "            'Title', 'FamilySize'],\n",
    "        degree=2)),\n",
    "    ('CleanCatego', BinRareCategories(min_ratio=0.)),\n",
    "    ('Encoder', WOEEncoder(add_missing_categories=True)),\n",
    "]\n",
    "\n",
    "pipe = Pipeline(steps=steps, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/titanic.parquet')\n",
    "data = data.reset_index(drop=True)\n",
    "y = data['Survived']\n",
    "X = data.drop('Survived', axis=1)\n",
    "train_test_split = TrainTestSplit(test_ratio=0.3, strategy='ordered')\n",
    "X_train, X_test, y_train, y_test = train_test_split.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepro_pd = pipe.fit_transform(X_train, y_train)\n",
    "X_test_prepro_pd = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "client = dask.distributed.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dd = dd.read_parquet('data/titanic.parquet')\n",
    "data_dd = data_dd.reset_index(drop=True)\n",
    "y_dd = data_dd['Survived']\n",
    "X_dd = data_dd.drop('Survived', axis=1)\n",
    "\n",
    "train_test_split = TrainTestSplit(test_ratio=0.3, strategy='ordered')\n",
    "X_train_dd, X_test_dd, y_train_dd, y_test_dd = train_test_split.transform(X_dd, y_dd)\n",
    "X_train_dd = client.persist(X_train_dd)\n",
    "X_test_dd = client.persist(X_test_dd)\n",
    "y_train_dd = client.persist(y_train_dd)\n",
    "y_test_dd = client.persist(y_test_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepro_dd = pipe.fit_transform(X_train_dd, y_train_dd)\n",
    "X_test_prepro_dd = pipe.transform(X_test_dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koalas pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/cpoli/gators38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/25 11:40:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '2g')\n",
    "conf.set('spark.sql.codegen.wholeStage', 'false')\n",
    "SparkContext(conf=conf)\n",
    "import databricks.koalas as ks\n",
    "ks.set_option('compute.default_index_type', 'distributed-sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: 3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark<3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_ks = ks.read_parquet('data/titanic.parquet')\n",
    "data_ks = data_ks.reset_index(drop=True)\n",
    "y_ks = data_ks['Survived']\n",
    "X_ks = data_ks.drop('Survived', axis=1)\n",
    "train_test_split = TrainTestSplit(test_ratio=0.3, strategy='ordered')\n",
    "X_train_ks, X_test_ks, y_train_ks, y_test_ks = train_test_split.transform(X_ks, y_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpoli/gators38/lib/python3.8/site-packages/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "22/01/25 11:41:05 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "/Users/cpoli/gators38/lib/python3.8/site-packages/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_prepro_ks = pipe.fit_transform(X_train_ks, y_train_ks)\n",
    "X_test_prepro_ks = pipe.transform(X_test_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check results match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check pandas, dask, and koalas results match - production pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 162:=========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert_frame_equal(\n",
    "    X_train_prepro_pd,\n",
    "    X_train_prepro_ks.to_pandas())\n",
    "assert_frame_equal(\n",
    "    X_train_prepro_pd,\n",
    "    X_train_prepro_dd.compute())\n",
    "assert_frame_equal(\n",
    "    X_test_prepro_pd,\n",
    "    X_test_prepro_dd.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert_frame_equal(\n",
    "    X_test_prepro_pd.reset_index(drop=True),\n",
    "    X_test_prepro_ks.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gators38",
   "language": "python",
   "name": "gators38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
